## FROM:[缓存更新的套路](https://coolshell.cn/articles/17416.html)

## 问题做法
- 先删除cache，然后更新database,再更新cache
  - 问题：两个并发操作，一个是更新操作，一个查询操作。更新操作删除cache后，查询操作没有命中cache，把old data读出来放到cache。然后更新database。导致cache中的data是
  旧数据，而且一直都是旧数据
  
## 假设更新数据库和更新缓存都可以成功的情况

## Cache Aside Pattern
- 失效：app先从cache取data，没有，就从database中取data，成功后放到cache中
- 命中：app从cache取data，去到后返回
- 更新：先把data存到database,成功后，再让cache失效
  - 分析：一个查询操作，一个更新操作。首先没有了删除cache操作而且先更新database，此时cache已然有效。所以并发查询并没有拿出更新后的data。但是并发更新操作让cache失效，后续的查询再把database中拉出来。所以没有导致后续的查询一直都在取old data。
  - 参考1：[Scaling Memcache at Facebook](https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf) 
  - 参考2：[Why does Facebook use delete to remove the key-value pair in Memcached instead of updating the Memcached during write request to the backend](https://www.quora.com/Why-does-Facebook-use-delete-to-remove-the-key-value-pair-in-Memcached-instead-of-updating-the-Memcached-during-write-request-to-the-backend)
- 问题：一个读操作，但是没有命中cache，那么去database取数据。这个时候来了个写操作，让缓存失效。然后之前那个读操作再把老数据放进去(前面已经取出来了)。所以造成脏数据。
不过呢，这种情况出现的概率比较低。读多于写，读快于写。
- 缺点：app那边要维护两个数据存储，一个是cache，一个database。导致app代码会比较啰嗦
- ```python
  def read(key):
    data = cache.get(key)
    if not data:
        data = db.get()
        cache.put(key,data)
    else:
        return data
        
  def update(key,new_data):
    db.write(key,new_data)
    cache.delete()
    ```
    
## Read/Write Through Pattern
### Read Through
Read Through 套路就是在查询操作中更新缓存，也就是说，当缓存失效的时候（过期或LRU换出），
Cache Aside是由调用方负责把数据加载入缓存，而Read Through则用缓存服务自己来加载，从而对应用方是透明的。

### Write Through
Write Through 套路和Read Through相仿，不过是在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。
如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作）

[示例图](https://github.com/xiazhibin/blog/blob/master/pic/read:write_through.jpg)

## Write Behind Caching Pattern
在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。
[示例图](https://github.com/xiazhibin/blog/blob/master/pic/write_back.jpg)

## 更新Cache成功，更新数据库失败了怎么吗？或是反过来
使用“两阶段提交协议”——prepare, commit/rollback

## 缓存常见问题
### 缓存穿透
客户端不断查询一个不存在的id，那么缓存每次都会失效，请求直接到达数据库
#### 应对
当遇到这个的情况的可以设置一个标记，例如“&&”，“no_key”这样的

### 缓存并发
一个缓存如果失效，可能出现多个进程同时查询DB，同时设置缓存的情况，如果并发确实很大，这也可能造成DB压力过大，还有缓存频繁更新的问题。
#### 应对
对缓存查询加锁，如果KEY不存在，就加锁，然后查DB，然后解锁。其他并发查询等待锁，等解锁后就直接返回数据或者入DB查询了。
```python
def cache_get(key):
    mutex_key = 'mutex_{}'.format(key)
    while_time = 0
    while while_time > 3:
        value = redis_client.get(key)
        if value is None:
            rv = redis_client.setnx(mutex_key, mutex_key)
            if rv:
                new_value = db.get()
                redis_client.set(key, new_value, ex=3)
                redis_client.delete(mutex_key)
                return value
            else:
                time.sleep(0.1)
        else:
            return value
        while_time += 1
    return None
```

### 缓存失效
缓存过期时间一致，导致很多缓存同时失效
#### 应对
给缓存时间加个random值，让缓存失效时间尽量分布均匀点。

### 缓存一致性问题
#### 应对
先写数据库，再修改缓存。修改数据库成功，而修改缓存失败，可能是缓存服务器挂了，可能是网络问题没有导致及时更新。
- 网络问题，可以通过重试机制解决。再次从数据库读入数据
- 缓存服务器挂了，这时候可以将这个数据放到数据库中，同时启动一个异步任务定时去检测缓存服务器是否连接成功，一旦连接成功则从数据库中按顺序取出修改数据，依次进行缓存最新值的修改。或者直接从数据库读入更新数据
